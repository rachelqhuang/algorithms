{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to calculate AUC from scratch (no ML package used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC is referring to Area Under Receiver Operating Curve. It is often used to measure prediction accuracy of classification problems. The good thing about AUC is that it shows the result for all possible cut-offs when it comes to decide the optimal cut-off threshold.\n",
    "\n",
    "This is a great video explaining AUC\n",
    "http://www.dataschool.io/roc-curves-and-auc-explained/\n",
    "\n",
    "This notebook is to calculate AUC without using any dependency package. The result will be tested on a sample dataset and be compared to the result calcuated by Sciki-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: calculate true positive rate and false positive rate for each user_defined cut-off threshold\n",
    "\n",
    "- TP rate =  TP/(TP + FN) \n",
    "- FP rate = FP/(FP + TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def true_pos_rate(actual_score_array, prediction_score_array, threshold):\n",
    "    \n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    if len(actual_score_array) != len(prediction_score_array):\n",
    "        print(\"warning: actual array and score array need to have the same length!\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for y, y_hat in zip(actual_score_array, prediction_score_array):\n",
    "            \n",
    "            if y == 1 and y_hat > threshold:\n",
    "                TP += 1\n",
    "            elif y ==1 and y_hat < threshold:\n",
    "                FN += 1\n",
    "            else:\n",
    "                TP += 0\n",
    " \n",
    "        return TP * 1.000/(TP + FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def false_pos_rate(actual_score_array, prediction_score_array, threshold):\n",
    "    \n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    \n",
    "    if len(actual_score_array) != len(prediction_score_array):\n",
    "        print(\"warning: actual array and score array need to have the same length!\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for y, y_hat in zip(actual_score_array, prediction_score_array):\n",
    "            \n",
    "            if y == 0 and y_hat >= threshold:\n",
    "                FP += 1\n",
    "            elif y ==0 and y_hat <= threshold:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 0\n",
    " \n",
    "        return FP * 1.000/(FP + TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: use the calcuated true and false positive rate to calculate the auc\n",
    "threshold_list is defined by the user, step size can be as small as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc_cal(actual_score_array,prediction_score_array,threshold_list):\n",
    "    tpr_list = []\n",
    "    fpr_list = []\n",
    "    \n",
    "    # generate a list of tpr, generate a list of fpr\n",
    "    for th in threshold_list:\n",
    "        \n",
    "        tpr_list.append(true_pos_rate(actual_score_array,prediction_score_array,th))\n",
    "        fpr_list.append(false_pos_rate(actual_score_array,prediction_score_array,th))\n",
    "        \n",
    "    # generate true positive list (substract the previous tpr)\n",
    "    tpr_list_substract = [tpr_list[i]-tpr_list[i+1] for i in range(len(tpr_list)-1)]\n",
    "    tpr_list_substract.insert(len(tpr_list)-1,tpr_list[len(tpr_list) -1])\n",
    "    \n",
    "    # generate false positive list (subtract the previous fpr)\n",
    "    fpr_list_substract = [fpr_list[i]-fpr_list[i+1] for i in range(len(fpr_list)-1)]\n",
    "    fpr_list_substract.insert(len(fpr_list)-1,fpr_list[len(fpr_list) -1])\n",
    "    \n",
    "    # take the first element and onwards\n",
    "    tpr_remove_the_largest = tpr_list[1:]\n",
    "    tpr_remove_the_largest.insert(len(tpr_remove_the_largest)-1, tpr_list[len(tpr_list) -1])\n",
    "    \n",
    "    #calculate area under the curve\n",
    "    auc = (0.5 *(np.array(tpr_list_substract).dot(np.array(fpr_list_substract))) + np.array(tpr_remove_the_largest).dot(np.array(fpr_list_substract)))\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the result on randomly generated dummy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_actual are:\n",
      "[1 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1\n",
      " 0 1 0 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 0 1 0 1 0 1 0 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1]\n",
      "y_scores are:\n",
      "[ 0.02170709  0.79349882  0.15634267  0.41640273  0.83401201  0.16093844\n",
      "  0.57689871  0.90580256  0.17949482  0.2368067   0.05524144  0.26409155\n",
      "  0.27863757  0.10994987  0.744952    0.57874802  0.13196928  0.51246108\n",
      "  0.3633696   0.4788283   0.66882581  0.30107823  0.34787405  0.5724247\n",
      "  0.41520884  0.46827663  0.25271672  0.53814267  0.21144478  0.67944208\n",
      "  0.80328112  0.43497804  0.18578928  0.55703032  0.426147    0.72973414\n",
      "  0.02622692  0.86876235  0.60307218  0.15187998  0.65145489  0.86844425\n",
      "  0.11961548  0.24071914  0.62225687  0.58213272  0.85592275  0.63668841\n",
      "  0.20810597  0.71954138  0.18401001  0.56739185  0.02934028  0.78666915\n",
      "  0.11736302  0.62143267  0.48719313  0.81749175  0.56467944  0.32878933\n",
      "  0.65248722  0.9553407   0.46015237  0.32443096  0.36180582  0.47701873\n",
      "  0.63717424  0.10271248  0.53720547  0.66207242  0.09932439  0.9709532\n",
      "  0.72469073  0.44992536  0.93840314  0.25487772  0.40017217  0.45210274\n",
      "  0.65672951  0.42758929  0.76418064  0.8734517   0.01778073  0.15935175\n",
      "  0.75223597  0.07997561  0.13543191  0.81362332  0.99090201  0.36147692\n",
      "  0.79456994  0.70419323  0.07097107  0.73019748  0.04412681  0.17572711\n",
      "  0.94006017  0.35413243  0.66866553  0.78104115]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# create a dummy prediction set and dummy threshold list\n",
    "y_true = np.random.randint(2, size=100)\n",
    "print(\"y_actual are:\")\n",
    "print(y_true)\n",
    "y_scores = np.array([random.random() for i in range(100)])\n",
    "print(\"y_scores are:\")\n",
    "print(y_scores)\n",
    "threshold_list = np.linspace(0,1,1000,endpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC using Sciki-learn package is:0.5163636363636364\n",
      "AUC using raw functions I built is:0.5165656565656566\n"
     ]
    }
   ],
   "source": [
    "# calculate AUC using the SKLEARN package\n",
    "print(\"AUC using Sciki-learn package is:{}\".format(roc_auc_score(y_true, y_scores)))\n",
    "\n",
    "# calculate AUC using the raw functions above\n",
    "print(\"AUC using raw functions I built is:{}\".format(auc_cal(y_true,y_scores,threshold_list)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
